name: CI

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

permissions:
  contents: read

jobs:
  validate-progressive-disclosure:
    name: Validate Progressive Disclosure Architecture
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Run progressive disclosure validation
        id: validation
        run: |
          chmod +x scripts/validate-progressive-disclosure.sh
          ./scripts/validate-progressive-disclosure.sh | tee validation-output.txt
          echo "result=$?" >> $GITHUB_OUTPUT
        env:
          RUN_PROJECT_TEST: "true"
        continue-on-error: true

      - name: Generate validation summary
        if: always()
        run: |
          echo "## üìã Progressive Disclosure Validation" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ "${{ steps.validation.outputs.result }}" == "0" ]; then
            echo "‚úÖ **Status:** PASSED" >> $GITHUB_STEP_SUMMARY
          else
            echo "‚ùå **Status:** FAILED" >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Tests Performed" >> $GITHUB_STEP_SUMMARY
          echo "- Directory structure validation" >> $GITHUB_STEP_SUMMARY
          echo "- **Claude:** AGENTS.md + hierarchical rules" >> $GITHUB_STEP_SUMMARY
          echo "- **Cursor:** .cursorrules generation" >> $GITHUB_STEP_SUMMARY
          echo "- **Copilot:** .github/copilot-instructions.md" >> $GITHUB_STEP_SUMMARY
          echo "- Base rules language-agnostic validation" >> $GITHUB_STEP_SUMMARY
          echo "- Documentation completeness check" >> $GITHUB_STEP_SUMMARY
          echo "- Real project integration test (all 3 AI tools)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ -f validation-output.txt ]; then
            echo "<details>" >> $GITHUB_STEP_SUMMARY
            echo "<summary>View detailed output</summary>" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
            tail -100 validation-output.txt >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
            echo "</details>" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload validation results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: validation-results
          path: |
            validation-output.txt
            .claude/
            scripts/
          retention-days: 5

      - name: Fail if validation failed
        if: steps.validation.outputs.result != '0'
        run: exit 1

  shellcheck:
    name: ShellCheck Linting
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Run ShellCheck on all shell scripts
        id: shellcheck-scripts
        uses: ludeeus/action-shellcheck@master
        with:
          scandir: './scripts'
          severity: warning
          format: gcc
        continue-on-error: true

      - name: Run ShellCheck on sync script
        id: shellcheck-sync
        uses: ludeeus/action-shellcheck@master
        with:
          check_together: 'yes'
          scandir: '.'
          format: gcc
          severity: warning
        env:
          SHELLCHECK_OPTS: -e SC2086
        continue-on-error: true

      - name: Generate ShellCheck summary
        if: always()
        run: |
          echo "## üîç ShellCheck Linting Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          scripts_status="${{ steps.shellcheck-scripts.outcome }}"
          sync_status="${{ steps.shellcheck-sync.outcome }}"

          if [ "$scripts_status" == "success" ] && [ "$sync_status" == "success" ]; then
            echo "‚úÖ **Status:** ALL CHECKS PASSED" >> $GITHUB_STEP_SUMMARY
          else
            echo "‚ùå **Status:** ISSUES FOUND" >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Scanned Files" >> $GITHUB_STEP_SUMMARY
          echo "- **Scripts directory:** $scripts_status" >> $GITHUB_STEP_SUMMARY
          echo "- **Sync script (root):** $sync_status" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Checks Performed" >> $GITHUB_STEP_SUMMARY
          echo "- Syntax errors" >> $GITHUB_STEP_SUMMARY
          echo "- Common pitfalls (SC codes)" >> $GITHUB_STEP_SUMMARY
          echo "- Best practices violations" >> $GITHUB_STEP_SUMMARY
          echo "- Security issues" >> $GITHUB_STEP_SUMMARY

      - name: Fail if ShellCheck found issues
        if: steps.shellcheck-scripts.outcome != 'success' || steps.shellcheck-sync.outcome != 'success'
        run: exit 1

  test-sync-script:
    name: Test Sync Script
    runs-on: ubuntu-latest
    strategy:
      matrix:
        include:
          # ===== BASIC LANGUAGE + FRAMEWORK TESTS =====
          - name: "Python + FastAPI"
            project-type: python-fastapi
            scenario: basic
            expected-rules: "python, fastapi, testing"
            setup: |
              cat > pyproject.toml <<'EOF'
              [project]
              name = "test-project"
              version = "0.1.0"
              dependencies = ["fastapi", "pytest"]
              EOF
              mkdir -p src
              echo 'from fastapi import FastAPI' > src/main.py

          - name: "TypeScript + React"
            project-type: typescript-react
            scenario: basic
            expected-rules: "typescript, react, testing"
            setup: |
              cat > package.json <<'EOF'
              {
                "name": "test-project",
                "version": "1.0.0",
                "dependencies": {
                  "react": "^18.0.0",
                  "typescript": "^5.0.0"
                }
              }
              EOF
              mkdir -p src
              echo 'import React from "react";' > src/App.tsx

          - name: "Go + Standard Library"
            project-type: go-stdlib
            scenario: basic
            expected-rules: "go, testing"
            setup: |
              cat > go.mod <<'EOF'
              module example.com/test
              go 1.21
              EOF
              mkdir -p cmd
              echo 'package main' > cmd/main.go

          # ===== CLOUD PLATFORM TESTS =====
          - name: "Python + FastAPI + AWS"
            project-type: python-fastapi-aws
            scenario: cloud-aws
            expected-rules: "python, fastapi, aws, security"
            setup: |
              cat > pyproject.toml <<'EOF'
              [project]
              name = "api"
              dependencies = ["fastapi", "boto3", "pytest"]
              EOF
              mkdir -p src
              echo 'from fastapi import FastAPI' > src/main.py
              echo 'import boto3' > src/aws_client.py
              cat > aws-config.yml <<'EOF'
              region: us-east-1
              services: [s3, dynamodb]
              EOF

          - name: "TypeScript + React + Vercel"
            project-type: typescript-react-vercel
            scenario: cloud-vercel
            expected-rules: "typescript, react, vercel, performance"
            setup: |
              cat > package.json <<'EOF'
              {
                "name": "frontend",
                "dependencies": {
                  "react": "^18.0.0",
                  "typescript": "^5.0.0"
                }
              }
              EOF
              cat > vercel.json <<'EOF'
              {
                "version": 2,
                "builds": [{"src": "src/**", "use": "@vercel/static"}]
              }
              EOF
              mkdir -p src
              echo 'import React from "react";' > src/App.tsx

          - name: "Python + Django + GCP"
            project-type: python-django-gcp
            scenario: cloud-gcp
            expected-rules: "python, django, cloud, security"
            setup: |
              cat > pyproject.toml <<'EOF'
              [project]
              name = "app"
              dependencies = ["django", "google-cloud-storage", "pytest"]
              EOF
              cat > app.yaml <<'EOF'
              runtime: python39
              env: standard
              EOF
              mkdir -p src
              echo 'from django.conf import settings' > src/settings.py

          - name: "Java + SpringBoot + Azure"
            project-type: java-springboot-azure
            scenario: cloud-azure
            expected-rules: "java, springboot, cloud, security"
            setup: |
              cat > pom.xml <<'EOF'
              <project>
                <modelVersion>4.0.0</modelVersion>
                <groupId>com.example</groupId>
                <artifactId>demo</artifactId>
                <version>1.0.0</version>
                <dependencies>
                  <dependency>
                    <groupId>org.springframework.boot</groupId>
                    <artifactId>spring-boot-starter-web</artifactId>
                  </dependency>
                  <dependency>
                    <groupId>com.azure</groupId>
                    <artifactId>azure-storage-blob</artifactId>
                  </dependency>
                </dependencies>
              </project>
              EOF
              mkdir -p src/main/java
              echo 'package com.example;' > src/main/java/Application.java

          - name: "TypeScript + Express + AWS"
            project-type: typescript-express-aws
            scenario: cloud-aws-api
            expected-rules: "typescript, express, aws, security"
            setup: |
              cat > package.json <<'EOF'
              {
                "name": "api",
                "dependencies": {
                  "express": "^4.18.0",
                  "typescript": "^5.0.0",
                  "aws-sdk": "^2.0.0"
                }
              }
              EOF
              mkdir -p src
              echo 'import express from "express";' > src/server.ts
              echo 'import AWS from "aws-sdk";' > src/aws.ts

          # ===== SCENARIO-BASED TESTS =====
          - name: "Python Refactoring Scenario"
            project-type: python-refactoring
            scenario: refactoring
            expected-rules: "python, refactoring-patterns, code-quality"
            setup: |
              cat > pyproject.toml <<'EOF'
              [project]
              name = "legacy-app"
              dependencies = ["pytest", "pylint", "black"]
              EOF
              mkdir -p src tests
              cat > src/legacy_code.py <<'EOF'
              # Legacy code needing refactoring
              def process_data(data):
                  # TODO: Refactor this complex function
                  result = []
                  for item in data:
                      if item > 0:
                          result.append(item * 2)
                  return result
              EOF
              echo '# Tests for refactored code' > tests/test_legacy.py

          - name: "TypeScript Performance Optimization"
            project-type: typescript-performance
            scenario: performance
            expected-rules: "typescript, performance, testing"
            setup: |
              cat > package.json <<'EOF'
              {
                "name": "app",
                "dependencies": {
                  "typescript": "^5.0.0"
                },
                "devDependencies": {
                  "benchmark": "^2.1.4"
                }
              }
              EOF
              mkdir -p src benchmarks
              cat > src/slow-algorithm.ts <<'EOF'
              // Performance optimization needed
              export function slowSort(arr: number[]): number[] {
                // Bubble sort - needs optimization
                return arr.sort((a, b) => a - b);
              }
              EOF
              echo 'import Benchmark from "benchmark";' > benchmarks/perf.ts

          - name: "Go Security Hardening"
            project-type: go-security
            scenario: security
            expected-rules: "go, security-principles, testing"
            setup: |
              cat > go.mod <<'EOF'
              module example.com/secure-app
              go 1.21
              require (
                golang.org/x/crypto v0.17.0
              )
              EOF
              mkdir -p cmd internal
              cat > cmd/main.go <<'EOF'
              package main
              import "crypto/rand"
              // Security-sensitive application
              func main() {
                // TODO: Implement secure token generation
              }
              EOF

          - name: "Python Debugging & Testing"
            project-type: python-debugging
            scenario: debugging
            expected-rules: "python, testing-philosophy, code-quality"
            setup: |
              cat > pyproject.toml <<'EOF'
              [project]
              name = "buggy-app"
              dependencies = ["pytest", "pytest-cov", "pdb"]
              EOF
              mkdir -p src tests
              cat > src/calculator.py <<'EOF'
              # Buggy calculator needing debugging
              def divide(a, b):
                  return a / b  # Bug: No zero division check
              EOF
              cat > tests/test_calculator.py <<'EOF'
              import pytest
              from src.calculator import divide

              def test_divide_by_zero():
                  # This test should help identify the bug
                  with pytest.raises(ZeroDivisionError):
                      divide(10, 0)
              EOF

          # ===== MULTI-CLOUD & COMPLEX SCENARIOS =====
          - name: "Multi-Cloud (AWS + GCP)"
            project-type: multi-cloud
            scenario: multi-cloud
            expected-rules: "python, aws, cloud, architecture"
            setup: |
              cat > pyproject.toml <<'EOF'
              [project]
              name = "multi-cloud-app"
              dependencies = ["boto3", "google-cloud-storage", "pytest"]
              EOF
              mkdir -p src/aws src/gcp
              echo 'import boto3' > src/aws/s3_client.py
              echo 'from google.cloud import storage' > src/gcp/gcs_client.py
              cat > cloud-config.yml <<'EOF'
              providers:
                - aws
                - gcp
              EOF

          - name: "Python + Django + PostgreSQL"
            project-type: python-django-postgres
            scenario: database
            expected-rules: "python, django, testing, architecture"
            setup: |
              cat > pyproject.toml <<'EOF'
              [project]
              name = "app"
              dependencies = ["django", "psycopg2-binary", "pytest"]
              EOF
              cat > requirements.txt <<'EOF'
              Django>=4.2
              psycopg2-binary>=2.9
              EOF

          - name: "TypeScript + Next.js + Vercel (Full Stack)"
            project-type: typescript-nextjs-vercel
            scenario: fullstack-vercel
            expected-rules: "typescript, react, vercel, performance"
            setup: |
              cat > package.json <<'EOF'
              {
                "name": "fullstack-app",
                "dependencies": {
                  "next": "14.0.0",
                  "react": "18.0.0",
                  "typescript": "5.0.0"
                }
              }
              EOF
              cat > vercel.json <<'EOF'
              {
                "version": 2,
                "framework": "nextjs"
              }
              EOF
              mkdir -p pages api
              echo 'import React from "react";' > pages/index.tsx
              echo 'export default function handler(req, res) {}' > api/hello.ts

          - name: "Go + Microservices + Docker + K8s"
            project-type: go-microservices
            scenario: microservices
            expected-rules: "go, architecture, 12-factor-app, cicd"
            setup: |
              cat > go.mod <<'EOF'
              module example.com/microservices
              go 1.21
              require (
                github.com/gin-gonic/gin v1.9.0
                github.com/prometheus/client_golang v1.17.0
              )
              EOF
              cat > Dockerfile <<'EOF'
              FROM golang:1.21-alpine
              WORKDIR /app
              COPY . .
              RUN go build -o service
              CMD ["./service"]
              EOF
              mkdir -p k8s services/api
              cat > k8s/deployment.yml <<'EOF'
              apiVersion: apps/v1
              kind: Deployment
              metadata:
                name: api-service
              EOF
              echo 'package main' > services/api/main.go

          - name: "Rust + High Performance Computing"
            project-type: rust-hpc
            scenario: performance-critical
            expected-rules: "rust, performance, testing"
            setup: |
              cat > Cargo.toml <<'EOF'
              [package]
              name = "hpc-app"
              version = "0.1.0"
              edition = "2021"

              [dependencies]
              rayon = "1.8"

              [dev-dependencies]
              criterion = "0.5"
              EOF
              mkdir -p src benches
              echo 'fn main() {}' > src/main.rs
              echo 'use criterion::Criterion;' > benches/benchmark.rs

          - name: "C# + .NET + Azure Functions"
            project-type: csharp-azure-functions
            scenario: serverless-azure
            expected-rules: "csharp, cloud, architecture"
            setup: |
              cat > project.csproj <<'EOF'
              <Project Sdk="Microsoft.NET.Sdk">
                <PropertyGroup>
                  <TargetFramework>net8.0</TargetFramework>
                  <AzureFunctionsVersion>v4</AzureFunctionsVersion>
                </PropertyGroup>
                <ItemGroup>
                  <PackageReference Include="Microsoft.Azure.Functions.Worker" Version="1.20.0" />
                </ItemGroup>
              </Project>
              EOF
              mkdir -p src
              echo 'using Microsoft.Azure.Functions.Worker;' > src/Function.cs

          - name: "Multi-language (Python + TypeScript + Rust)"
            project-type: multi-lang-polyglot
            scenario: polyglot
            expected-rules: "python, typescript, rust, architecture"
            setup: |
              cat > pyproject.toml <<'EOF'
              [project]
              name = "backend"
              dependencies = ["fastapi"]
              EOF
              cat > package.json <<'EOF'
              {
                "name": "frontend",
                "dependencies": {"react": "18.0.0", "typescript": "5.0.0"}
              }
              EOF
              cat > Cargo.toml <<'EOF'
              [package]
              name = "compute-engine"
              version = "0.1.0"
              edition = "2021"
              EOF
              mkdir -p backend frontend compute/src
              echo 'from fastapi import FastAPI' > backend/main.py
              echo 'import React from "react";' > frontend/App.tsx
              echo 'fn main() {}' > compute/src/main.rs

          # ===== CI/CD & DEVOPS SCENARIOS =====
          - name: "Python + CI/CD Pipeline"
            project-type: python-cicd
            scenario: cicd
            expected-rules: "python, cicd-comprehensive, testing"
            setup: |
              cat > pyproject.toml <<'EOF'
              [project]
              name = "api"
              dependencies = ["fastapi", "pytest", "pytest-cov"]
              EOF
              mkdir -p .github/workflows src tests
              cat > .github/workflows/ci.yml <<'EOF'
              name: CI
              on: [push, pull_request]
              jobs:
                test:
                  runs-on: ubuntu-latest
                  steps:
                    - uses: actions/checkout@v4
                    - run: pytest
              EOF
              echo 'from fastapi import FastAPI' > src/main.py
              echo 'import pytest' > tests/test_main.py

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Create test project (${{ matrix.name }})
        run: |
          mkdir -p /tmp/test-project
          cd /tmp/test-project
          ${{ matrix.setup }}

      - name: Copy sync script to test project
        run: |
          cp sync-ai-rules.sh /tmp/test-project/
          chmod +x /tmp/test-project/sync-ai-rules.sh

      - name: Run sync script
        run: |
          cd /tmp/test-project
          ./sync-ai-rules.sh

      - name: Validate generated files
        id: validate
        run: |
          cd /tmp/test-project

          # Check AGENTS.md was generated
          if [ ! -f .claude/AGENTS.md ]; then
            echo "ERROR: .claude/AGENTS.md not generated"
            exit 1
          fi
          echo "‚úì AGENTS.md generated"

          # Check progressive disclosure instructions present
          if ! grep -q "DO NOT load all rule files at once" .claude/AGENTS.md; then
            echo "ERROR: Progressive disclosure warning missing"
            exit 1
          fi
          echo "‚úì Progressive disclosure warning present"

          # Check rules directory structure
          if [ ! -d .claude/rules ]; then
            echo "ERROR: .claude/rules directory not created"
            exit 1
          fi
          echo "‚úì Rules directory structure created"

          # Validate scenario-specific rules are referenced
          echo "Checking scenario-specific rules for: ${{ matrix.scenario }}"

          case "${{ matrix.scenario }}" in
            refactoring)
              if ! grep -qr "refactoring" .claude/rules/; then
                echo "WARNING: Refactoring scenario but no refactoring rules found"
              else
                echo "‚úì Refactoring rules present"
              fi
              ;;
            performance|performance-critical)
              if ! grep -qr "performance\|optimization" .claude/; then
                echo "WARNING: Performance scenario but no performance rules found"
              else
                echo "‚úì Performance rules present"
              fi
              ;;
            security)
              if ! grep -qr "security" .claude/rules/; then
                echo "WARNING: Security scenario but no security rules found"
              else
                echo "‚úì Security rules present"
              fi
              ;;
            cloud-*|multi-cloud|serverless-azure)
              if ! grep -qr "aws\|gcp\|azure\|vercel\|cloud" .claude/rules/; then
                echo "WARNING: Cloud scenario but no cloud-specific rules found"
              else
                echo "‚úì Cloud-specific rules present"
              fi
              ;;
            cicd)
              if ! grep -qr "ci.*cd\|cicd\|pipeline" .claude/; then
                echo "WARNING: CI/CD scenario but no CI/CD rules found"
              else
                echo "‚úì CI/CD rules present"
              fi
              ;;
            microservices)
              if ! grep -qr "12-factor\|architecture\|microservice" .claude/; then
                echo "WARNING: Microservices scenario but no architecture rules found"
              else
                echo "‚úì Architecture/microservices rules present"
              fi
              ;;
          esac

          # Check for cloud platform specific rules
          if [ -f "vercel.json" ]; then
            if [ -d ".claude/rules/cloud/vercel" ]; then
              echo "‚úì Vercel rules detected for Vercel project"
            else
              echo "WARNING: Vercel config found but no Vercel rules"
            fi
          fi

          if grep -q "boto3\|aws-sdk\|AWS" *.* 2>/dev/null; then
            if [ -d ".claude/rules/cloud/aws" ] || grep -qr "aws" .claude/rules/; then
              echo "‚úì AWS rules detected for AWS project"
            else
              echo "WARNING: AWS dependencies found but no AWS rules"
            fi
          fi

          if grep -q "google-cloud\|gcp" *.* 2>/dev/null; then
            if grep -qr "gcp\|google.*cloud" .claude/; then
              echo "‚úì GCP-related rules detected"
            else
              echo "WARNING: GCP dependencies found but no GCP rules"
            fi
          fi

          if grep -q "azure\|Microsoft.Azure" *.* 2>/dev/null; then
            if grep -qr "azure" .claude/; then
              echo "‚úì Azure-related rules detected"
            else
              echo "WARNING: Azure dependencies found but no Azure rules"
            fi
          fi

          # Validate language-specific rules
          if [ -f "pyproject.toml" ] || [ -f "requirements.txt" ]; then
            if [ -d ".claude/rules/languages/python" ]; then
              echo "‚úì Python rules detected"
            else
              echo "ERROR: Python project but no Python rules"
              exit 1
            fi
          fi

          if [ -f "package.json" ]; then
            if [ -d ".claude/rules/languages/typescript" ] || grep -q "typescript" .claude/rules/ -r; then
              echo "‚úì TypeScript/JavaScript rules detected"
            else
              echo "ERROR: Node.js project but no TypeScript rules"
              exit 1
            fi
          fi

          if [ -f "go.mod" ]; then
            if [ -d ".claude/rules/languages/go" ]; then
              echo "‚úì Go rules detected"
            else
              echo "ERROR: Go project but no Go rules"
              exit 1
            fi
          fi

          if [ -f "Cargo.toml" ]; then
            if [ -d ".claude/rules/languages/rust" ]; then
              echo "‚úì Rust rules detected"
            else
              echo "ERROR: Rust project but no Rust rules"
              exit 1
            fi
          fi

          if [ -f "pom.xml" ] || [ -f "*.csproj" ]; then
            if [ -d ".claude/rules/languages/java" ] || [ -d ".claude/rules/languages/csharp" ]; then
              echo "‚úì Java/C# rules detected"
            else
              echo "WARNING: JVM/.NET project but rules may be missing"
            fi
          fi

          # Check framework-specific rules
          if grep -q "fastapi" pyproject.toml 2>/dev/null || grep -q "from fastapi" src/*.py 2>/dev/null; then
            if [ -d ".claude/rules/frameworks/fastapi" ]; then
              echo "‚úì FastAPI rules detected"
            fi
          fi

          if grep -q "django" pyproject.toml requirements.txt 2>/dev/null; then
            if [ -d ".claude/rules/frameworks/django" ]; then
              echo "‚úì Django rules detected"
            fi
          fi

          if grep -q '"react"' package.json 2>/dev/null; then
            if [ -d ".claude/rules/frameworks/react" ]; then
              echo "‚úì React rules detected"
            fi
          fi

          if grep -q '"express"' package.json 2>/dev/null; then
            if [ -d ".claude/rules/frameworks/express" ]; then
              echo "‚úì Express rules detected"
            fi
          fi

          if grep -q "spring-boot" pom.xml 2>/dev/null; then
            if [ -d ".claude/rules/frameworks/springboot" ]; then
              echo "‚úì SpringBoot rules detected"
            fi
          fi

          echo "‚úÖ All validations passed for ${{ matrix.name }}"
        continue-on-error: true

      - name: Generate test summary
        if: always()
        run: |
          echo "## üß™ Sync Script Test: ${{ matrix.name }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ "${{ steps.validate.outcome }}" == "success" ]; then
            echo "‚úÖ **Status:** PASSED" >> $GITHUB_STEP_SUMMARY
          else
            echo "‚ùå **Status:** FAILED" >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Test Details" >> $GITHUB_STEP_SUMMARY
          echo "- **Project Type:** ${{ matrix.name }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Scenario:** \`${{ matrix.scenario }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Expected Rules:** ${{ matrix.expected-rules }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Validations Performed" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úì AGENTS.md generation" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úì Progressive disclosure warnings" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úì Rules directory structure" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úì Language/framework detection" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úì Scenario-specific rules validation" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úì Cloud platform rules (if applicable)" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úì Context-appropriate rule application" >> $GITHUB_STEP_SUMMARY

      - name: Fail if validation failed
        if: steps.validate.outcome != 'success'
        run: exit 1

      - name: Upload test artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-project-${{ matrix.project-type }}
          path: /tmp/test-project/.claude/
          retention-days: 5

  verify-documentation:
    name: Verify Documentation
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Check README mentions progressive disclosure
        id: check-readme
        run: |
          if ! grep -qi "progressive disclosure" README.md; then
            echo "ERROR: README.md doesn't mention progressive disclosure"
            exit 1
          fi
          echo "‚úì README.md documents progressive disclosure"
        continue-on-error: true

      - name: Check ARCHITECTURE documentation
        id: check-arch
        run: |
          if [ -f ARCHITECTURE.md ]; then
            if ! grep -qi "progressive disclosure" ARCHITECTURE.md; then
              echo "ERROR: ARCHITECTURE.md doesn't explain progressive disclosure"
              exit 1
            fi
            echo "‚úì ARCHITECTURE.md explains progressive disclosure"
          else
            echo "WARNING: ARCHITECTURE.md not found"
          fi
        continue-on-error: true

      - name: Verify rule files are markdown
        id: check-markdown
        run: |
          # Check that all rule files are .md
          non_md=$(find base/ languages/ frameworks/ cloud/ -type f ! -name "*.md" 2>/dev/null || true)
          if [ -n "$non_md" ]; then
            echo "ERROR: Non-markdown files found in rule directories:"
            echo "$non_md"
            exit 1
          fi
          echo "‚úì All rule files are markdown"
        continue-on-error: true

      - name: Check for broken internal links
        id: check-links
        run: |
          # Simple check for broken relative links in markdown files
          for file in $(find . -name "*.md" -not -path "./node_modules/*" -not -path "./.claude/*"); do
            echo "Checking $file..."
            # This is a basic check - could be enhanced with a proper link checker
            if grep -o '\[.*\](\.\/[^)]*\.md)' "$file" > /dev/null; then
              echo "  Found internal links"
            fi
          done
          echo "‚úì Internal link check complete"
        continue-on-error: true

      - name: Generate documentation verification summary
        if: always()
        run: |
          echo "## üìö Documentation Verification" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          readme="${{ steps.check-readme.outcome }}"
          arch="${{ steps.check-arch.outcome }}"
          markdown="${{ steps.check-markdown.outcome }}"
          links="${{ steps.check-links.outcome }}"

          if [ "$readme" == "success" ] && [ "$arch" == "success" ] && [ "$markdown" == "success" ] && [ "$links" == "success" ]; then
            echo "‚úÖ **Status:** ALL CHECKS PASSED" >> $GITHUB_STEP_SUMMARY
          else
            echo "‚ùå **Status:** SOME CHECKS FAILED" >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Documentation Checks" >> $GITHUB_STEP_SUMMARY
          echo "- **README progressive disclosure:** $readme" >> $GITHUB_STEP_SUMMARY
          echo "- **ARCHITECTURE documentation:** $arch" >> $GITHUB_STEP_SUMMARY
          echo "- **Rule files are markdown:** $markdown" >> $GITHUB_STEP_SUMMARY
          echo "- **Internal links:** $links" >> $GITHUB_STEP_SUMMARY

      - name: Fail if any check failed
        if: steps.check-readme.outcome != 'success' || steps.check-arch.outcome != 'success' || steps.check-markdown.outcome != 'success' || steps.check-links.outcome != 'success'
        run: exit 1

  generate-test-report:
    name: Generate Test Report
    runs-on: ubuntu-latest
    needs:
      - validate-progressive-disclosure
      - shellcheck
      - test-sync-script
      - verify-documentation
    if: always()

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Generate comprehensive test report
        run: |
          cat > test-report.md << 'REPORT_EOF'
          # üöÄ CI Test Report

          **Workflow Run:** ${{ github.run_number }}
          **Commit:** `${{ github.sha }}`
          **Branch:** `${{ github.ref_name }}`
          **Triggered by:** ${{ github.event_name }}
          **Run Date:** $(date -u '+%Y-%m-%d %H:%M:%S UTC')

          ---

          ## üìä Test Results Summary

          | Test Suite | Status | Details |
          |-----------|---------|---------|
          | üìã Progressive Disclosure Validation | ${{ needs.validate-progressive-disclosure.result == 'success' && '‚úÖ PASSED' || '‚ùå FAILED' }} | Claude + Cursor + Copilot configs validated |
          | üîç ShellCheck Linting | ${{ needs.shellcheck.result == 'success' && '‚úÖ PASSED' || '‚ùå FAILED' }} | Bash script quality & security checks |
          | üß™ Sync Script Testing | ${{ needs.test-sync-script.result == 'success' && '‚úÖ PASSED' || '‚ùå FAILED' }} | **20+ comprehensive scenarios** (languages, cloud platforms, scenarios) |
          | üìö Documentation Verification | ${{ needs.verify-documentation.result == 'success' && '‚úÖ PASSED' || '‚ùå FAILED' }} | Documentation completeness & quality |

          ---

          ## üìã Progressive Disclosure Validation

          **Status:** ${{ needs.validate-progressive-disclosure.result == 'success' && '‚úÖ PASSED' || '‚ùå FAILED' }}

          ### Tests Performed
          - ‚úì Directory structure compliance (`base/`, `languages/`, `frameworks/`, `cloud/`)
          - ‚úì **Claude:** AGENTS.md configuration + hierarchical rules
          - ‚úì **Cursor:** .cursorrules file generation and content
          - ‚úì **Copilot:** .github/copilot-instructions.md generation
          - ‚úì Base rules language-agnostic verification
          - ‚úì Documentation completeness check
          - ‚úì Real project integration test (Python + FastAPI, all 3 AI tools)

          ### Artifacts
          - `validation-results` - Complete validation output and generated files

          ---

          ## üîç ShellCheck Linting

          **Status:** ${{ needs.shellcheck.result == 'success' && '‚úÖ PASSED' || '‚ùå FAILED' }}

          ### Scanned Files
          - Shell scripts in `scripts/` directory
          - Root-level `sync-ai-rules.sh`

          ### Checks Performed
          - ‚úì Syntax errors
          - ‚úì Common pitfalls (SC codes)
          - ‚úì Best practices violations
          - ‚úì Security issues

          ---

          ## üß™ Sync Script Testing

          **Status:** ${{ needs.test-sync-script.result == 'success' && '‚úÖ PASSED' || '‚ùå FAILED' }}

          ### Comprehensive Test Coverage

          #### üìö Basic Language + Framework Tests (3 scenarios)
          - Python + FastAPI
          - TypeScript + React
          - Go + Standard Library

          #### ‚òÅÔ∏è Cloud Platform Tests (5 scenarios)
          - **AWS:** Python + FastAPI + AWS, TypeScript + Express + AWS
          - **Vercel:** TypeScript + React + Vercel, TypeScript + Next.js + Vercel
          - **GCP:** Python + Django + GCP
          - **Azure:** Java + SpringBoot + Azure, C# + .NET + Azure Functions
          - **Multi-Cloud:** AWS + GCP integration

          #### üéØ Scenario-Based Tests (5 scenarios)
          - **Refactoring:** Python legacy code refactoring
          - **Performance:** TypeScript performance optimization, Rust HPC
          - **Security:** Go security hardening
          - **Debugging:** Python debugging & testing
          - **CI/CD:** Python with full CI/CD pipeline

          #### üèóÔ∏è Complex Architecture Tests (4 scenarios)
          - Microservices (Go + Docker + K8s)
          - Full-stack (TypeScript + Next.js + Vercel)
          - Database-driven (Python + Django + PostgreSQL)
          - Polyglot (Python + TypeScript + Rust)

          ### Total Test Scenarios: 20+

          ### Context-Aware Validations Per Project
          - ‚úì AGENTS.md generation with correct content
          - ‚úì Progressive disclosure warnings present
          - ‚úì Rules directory structure created
          - ‚úì Language/framework/cloud detection accuracy
          - ‚úì **Scenario-specific rules validation**
          - ‚úì **Cloud platform rules verification**
          - ‚úì **Context-appropriate rule application**
          - ‚úì **Multi-environment detection**

          ### Testing Approach
          The test suite validates that rules are applied contextually based on:
          - Programming language(s) in use
          - Framework(s) detected
          - Cloud platform(s) configured
          - Development scenario (refactoring, debugging, performance, etc.)
          - Architecture patterns (microservices, serverless, monolith)

          ### Artifacts
          - `test-project-*` - Generated `.claude/` directory for each project type (20+ artifacts)

          ---

          ## üìö Documentation Verification

          **Status:** ${{ needs.verify-documentation.result == 'success' && '‚úÖ PASSED' || '‚ùå FAILED' }}

          ### Checks Performed
          - ‚úì README.md mentions progressive disclosure
          - ‚úì ARCHITECTURE.md explains progressive disclosure design
          - ‚úì All rule files use `.md` extension
          - ‚úì Internal markdown links validation

          ---

          ## üéØ Overall Status

          REPORT_EOF

          # Determine overall status
          if [ "${{ needs.validate-progressive-disclosure.result }}" == "success" ] && \
             [ "${{ needs.shellcheck.result }}" == "success" ] && \
             [ "${{ needs.test-sync-script.result }}" == "success" ] && \
             [ "${{ needs.verify-documentation.result }}" == "success" ]; then
            echo "### ‚úÖ ALL TESTS PASSED" >> test-report.md
            echo "" >> test-report.md
            echo "All test suites completed successfully. The progressive disclosure architecture is validated and working correctly across all scenarios." >> test-report.md
            overall_status="success"
          else
            echo "### ‚ùå TESTS FAILED" >> test-report.md
            echo "" >> test-report.md
            echo "One or more test suites failed. Please review the individual test results above and check the workflow logs for details." >> test-report.md
            echo "" >> test-report.md
            echo "#### Failed Tests:" >> test-report.md
            [ "${{ needs.validate-progressive-disclosure.result }}" != "success" ] && echo "- Progressive Disclosure Validation" >> test-report.md
            [ "${{ needs.shellcheck.result }}" != "success" ] && echo "- ShellCheck Linting" >> test-report.md
            [ "${{ needs.test-sync-script.result }}" != "success" ] && echo "- Sync Script Testing" >> test-report.md
            [ "${{ needs.verify-documentation.result }}" != "success" ] && echo "- Documentation Verification" >> test-report.md
            overall_status="failure"
          fi

          echo "" >> test-report.md
          echo "---" >> test-report.md
          echo "" >> test-report.md
          echo "**Workflow URL:** https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}" >> test-report.md

          # Output to job summary
          cat test-report.md >> $GITHUB_STEP_SUMMARY

          # Save status for next step
          echo "status=$overall_status" >> $GITHUB_OUTPUT
        id: report

      - name: Upload test report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-report
          path: test-report.md
          retention-days: 30

      - name: Fail if tests failed
        if: steps.report.outputs.status != 'success'
        run: |
          echo "‚ùå One or more test suites failed"
          exit 1
