# Beads Integration: Deep Analysis & User Experience

## Executive Summary

The beads issue tracking rule has been integrated into centralized-rules with careful consideration for:
- **Progressive disclosure** - Rule is loaded on-demand, not by default
- **Clear integration** - Documented relationships with git-workflow, testing, and TodoWrite
- **User guidance** - AGENTS.md provides clear "when to load" instructions
- **Token efficiency** - 20KB rule loaded selectively at session boundaries

## End-User Journey

### Scenario 1: New Project Adopting Beads

**User story:** Developer starts using beads in their Python FastAPI project

```bash
# 1. User initializes beads in their project
cd ~/my-fastapi-project
bd init

# 2. User syncs centralized-rules
./sync-ai-rules.sh

# Output shows:
# â„¹ Detected languages: python
# â„¹ Detected frameworks: fastapi
# â„¹ Detected development tools: beads  ğŸ‘ˆ NEW!
# âœ“ Loaded beads issue tracking rules
```

**What happens:**
1. Script detects `.beads/` directory
2. Downloads `tools/beads/issue-tracking.md` â†’ `.ai-rules/.cache/tools/beads/`
3. Copies to `.claude/rules/tools/beads/issue-tracking.md`
4. Updates `.claude/AGENTS.md` with beads section:
   ```markdown
   - Development Tools: beads

   ### Development Tools

   **Beads (Issue Tracking):**
   - `tools/beads/issue-tracking.md` - Session protocols, issue creation
   - **When to load**: Session start/end, issue tracking
   - **Integration**: Works alongside git-workflow.md and TodoWrite tool
   ```

**AI agent experience:**
- Reads `.claude/AGENTS.md`
- Sees beads is available
- Knows **when** to load it (session boundaries, not always)
- Loads on-demand when user starts/ends sessions

### Scenario 2: Daily Development with AI Agent

**Morning session:**

```
User: "Let's start working today"

AI Agent:
1. Checks for .beads/ directory âœ“
2. Reads .claude/AGENTS.md - sees beads available
3. Loads beads rule (20KB) + git-workflow (8KB) = 28KB
4. Executes session start protocol:

ğŸ“š Rules Loaded for Session Start:
âœ“ Beads Issue Tracking (.claude/rules/tools/beads/issue-tracking.md)
âœ“ Git Workflow (.claude/rules/base/git-workflow.md)

Running session start protocol:
```bash
bd ready --json
```

Output shows 3 ready issues:
- bd-42 [P1]: Add user authentication
- bd-44 [P0]: Fix pagination bug
- bd-45 [P2]: Update dependencies

Which issue would you like to work on?
```

**Key insight:** AI agent knows to:
- Load beads rule at session start (not during every task)
- Follow beads protocols automatically
- Suggest available work using `bd ready --json`

**During work:**

```
User: "Work on bd-42"

AI Agent:
1. Claims issue: bd update bd-42 --status in_progress --json
2. Uses TodoWrite for tactical breakdown:
   - [pending] Create User model
   - [pending] Add auth endpoints
   - [pending] Write tests
3. While implementing, discovers validation bug
4. Immediately files it:
   bd create "Fix email validation" -t bug -p1 --json
   bd dep add bd-46 bd-42 --type discovered-from
5. Asks: "This bug blocks current work. Should I fix it now or defer?"
```

**Evening session end:**

```
User: "I'm done for today"

AI Agent:
1. Loads beads rule (if not already loaded)
2. Follows "Land the Plane" protocol:
   âœ“ Run tests: pytest tests/
   âœ“ Close completed issues: bd close bd-42 --reason "..."
   âœ“ File remaining work: bd create "Add integration tests" -t task -p2
   âœ“ Sync: bd sync
   âœ“ Push: git push
   âœ“ Verify: git status (clean)
   âœ“ Suggest next: bd ready --json

Session complete! Next session suggestions:
- bd-44 [P0]: Fix pagination bug (highest priority)
- bd-47 [P2]: Add integration tests (filed today)
```

### Scenario 3: Team Collaboration

**Multiple developers + AI agents:**

```
Developer A (with AI agent):
- Creates issue: bd create "Implement OAuth" -t feature -p1
- Works on it, pushes .beads/ metadata to git
- AI agent follows beads protocols

Developer B (with AI agent):
- Pulls changes: git pull
- Sees new issue: bd ready --json
- Both AI agents use same centralized-rules
- Consistent beads workflow across team
```

## Progressive Disclosure Strategy

### When Beads Rule is Loaded

**âœ… Load beads rule:**
- User says: "start session", "end session", "let's begin", "I'm done"
- User mentions: "bd", "beads", "issues", "create issue"
- User asks: "what should I work on?", "what's available?"
- Session boundary detected (morning/evening context)

**âŒ Don't load beads rule:**
- Normal coding tasks: "fix this function", "write a test"
- Code review: "review this component"
- Debugging: "why is this failing?"
- Simple questions: "how does this work?"

### Token Budget Management

**Typical session:**
```
Session Start:
  Beads rule: 20KB
  Git workflow: 8KB
  Total: 28KB
  Remaining: 172KB for code

Normal coding task (after session start):
  Don't reload beads rule (already in context)
  Load language-specific: Python 12KB
  Load framework: FastAPI 10KB
  Total: 22KB
  Remaining: 178KB for code

Session End:
  Beads rule: (already loaded)
  Git workflow: (already loaded)
  No additional tokens needed
```

**Comparison with always-loaded approach:**
```
âŒ If beads was always loaded:
  Every task: 20KB overhead
  10 tasks/session: 200KB wasted

âœ… With on-demand loading:
  Session boundaries only: 20KB once
  Savings: 180KB = 9x more code context!
```

## Integration Architecture

### The Four-Layer Stack

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 4: Beads Issue Tracking                              â”‚
â”‚ - Strategic: WHAT to work on                               â”‚
â”‚ - Cross-session persistence                                â”‚
â”‚ - Team-wide visibility (via git)                           â”‚
â”‚ - Scope: Features, bugs, tasks spanning days/weeks         â”‚
â”‚                                                             â”‚
â”‚ When to use: "What should I work on next?"                 â”‚
â”‚ Example: bd-42 "Implement user authentication"            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“ breaks down into â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 3: TodoWrite Task Management                         â”‚
â”‚ - Tactical: HOW to break down the work                     â”‚
â”‚ - Single-session scope                                      â”‚
â”‚ - AI agent only (not persisted)                            â”‚
â”‚ - Scope: Sub-tasks within a single issue                   â”‚
â”‚                                                             â”‚
â”‚ When to use: "How do I implement this issue?"              â”‚
â”‚ Example:                                                    â”‚
â”‚   - [pending] Create User model                            â”‚
â”‚   - [pending] Add auth endpoints                           â”‚
â”‚   - [pending] Write tests                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“ quality gates â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 2: Testing Philosophy                                â”‚
â”‚ - Quality: VERIFY work is correct                          â”‚
â”‚ - Required before marking tasks/issues complete            â”‚
â”‚ - Scope: All code changes                                  â”‚
â”‚                                                             â”‚
â”‚ When to use: Before closing any issue or task              â”‚
â”‚ Example: pytest tests/ â†’ all pass â†’ can close bd-42        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“ committed via â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 1: Git Workflow                                      â”‚
â”‚ - Foundation: VERSION CONTROL                              â”‚
â”‚ - Tracks both code AND .beads/ metadata                    â”‚
â”‚ - Scope: All changes                                        â”‚
â”‚                                                             â”‚
â”‚ When to use: Always (commit, push, clean state)            â”‚
â”‚ Example: git commit -m "feat: auth [bd-42]" && git push    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Cross-Layer Interactions

**1. Beads â†” Git:**
- `.beads/` directory is git-tracked
- `bd sync` = export to JSONL, commit, pull, import, push
- Beads session end requires `git push` (enforced)
- Commit messages reference beads issues: `[bd-42]`

**2. Beads â†” Testing:**
- Cannot close beads issue if tests fail
- Session end protocol runs quality gates
- Bug issues should include regression tests
- Testing issues tracked in beads

**3. Beads â†” TodoWrite:**
- Beads issue = strategic (what to work on)
- TodoWrite tasks = tactical (how to do it)
- Conversion: TodoWrite task spanning sessions â†’ beads issue
- Complementary, not competitive

**Example workflow combining all layers:**

```bash
# Layer 4: Beads - Strategic
bd ready --json
bd update bd-42 --status in_progress --json

# Layer 3: TodoWrite - Tactical
TodoWrite: [pending] Create User model
TodoWrite: [pending] Add auth endpoints
TodoWrite: [pending] Write tests

# Layer 2: Testing - Quality
pytest tests/  # Must pass

# Layer 1: Git - Foundation
git add .
git commit -m "feat: user model [bd-42]"

# Back to Layer 4: Complete issue
bd close bd-42 --reason "Implemented auth" --json
bd sync  # Uses git push internally
```

## Implementation Quality Analysis

### âœ… Strengths

1. **Proper detection:** `.beads/` directory check is reliable and simple
2. **Clean separation:** Tools category separate from languages/frameworks
3. **Comprehensive rule:** 20KB covers all beads workflows thoroughly
4. **Integration documentation:** Clear relationships with other rules
5. **Progressive disclosure:** AGENTS.md explains when to load
6. **Example-driven:** Usage examples in AGENTS.md
7. **Maturity levels:** MVP/Pre-Production/Production guidance

### âš ï¸ Considerations

1. **Rule size:** 20KB is large - must be loaded selectively
   - **Mitigation:** "When to Load" section added
   - **Guidance:** AGENTS.md specifies session boundaries

2. **Complexity:** Beads + Git + Testing + TodoWrite = 4 systems
   - **Mitigation:** Integration section explains relationships
   - **Guidance:** Visual stack diagram shows hierarchy

3. **Learning curve:** New users need to understand 4-layer stack
   - **Mitigation:** Progressive disclosure in AGENTS.md
   - **Guidance:** Examples show typical workflows

### ğŸ¯ Improvements Made

**Original implementation:**
- Created beads rule âœ“
- Added detection âœ“
- Updated rules-config.json âœ“

**Enhancements added:**
1. **AGENTS.md tools section:** Shows beads in detected tools list
2. **AGENTS.md integration guidance:** When to load, how it works with other rules
3. **AGENTS.md usage example:** Example 4 shows beads session workflow
4. **Beads rule integration section:** Comprehensive guide on working with git/testing/TodoWrite
5. **Progressive disclosure section:** Clear "when to load" criteria
6. **Token budget guidance:** Explains 20KB cost, when worth it

## User Experience Scenarios

### Scenario: AI Agent Session Management

**Context:** User has beads-enabled project, working with Claude Code

**Morning (Session Start):**

```
User: "Let's start coding"

Claude Code internal process:
1. Detects context: "start" keyword â†’ session start
2. Checks for .beads/ directory â†’ exists
3. Reads .claude/AGENTS.md â†’ sees beads available
4. Loads beads rule (20KB) - justified by session start
5. Executes protocol from rule:
   - Run: bd ready --json
   - Parse JSON output
   - Present available work to user
   - Help user claim issue

Claude: I see you have 3 issues ready to work on:

1. **bd-42** [P1] - Add user authentication
2. **bd-44** [P0] - Fix pagination bug (highest priority!)
3. **bd-45** [P2] - Update dependencies

I recommend starting with bd-44 (P0 bug). Shall I claim it?

User: "Yes, let's fix the bug"

Claude:
âœ“ Claimed: bd update bd-44 --status in_progress --json
âœ“ Issue is now in progress

I'll break this down into steps:
[Uses TodoWrite for tactical breakdown]
- [pending] Reproduce bug
- [pending] Write failing test
- [pending] Fix code
- [pending] Verify test passes
- [pending] Close issue

Let's start by reproducing the bug...
```

**During Work (Discovered Bug):**

```
Claude (while working on bd-44):
"I notice the user input validation is also broken. This is a separate bug.
Let me file it in beads:

bd create "Fix user input validation" \
  --description "Found while fixing bd-44: no validation on user input" \
  -t bug \
  -p 1 \
  --json

Created bd-47. I've linked it to bd-44 as discovered-from.

This doesn't block our current fix, so I'll continue with bd-44.
We can address bd-47 later."
```

**Evening (Session End):**

```
User: "I'm done for today"

Claude:
Running session end protocol...

âœ“ All tests passed: pytest tests/
âœ“ Closing issue: bd close bd-44 --reason "Fixed pagination..."
âœ“ Syncing: bd sync
âœ“ Pushing: git push
âœ“ Verified: git status clean

Session complete! Tomorrow's suggestions:
- bd-47 [P1]: Fix user input validation (discovered today)
- bd-42 [P1]: Add user authentication
- bd-45 [P2]: Update dependencies

Have a great evening! ğŸ‘‹
```

### Scenario: Team with Mixed Human/AI Development

**Team structure:**
- 2 human developers
- 1 AI agent (Claude Code)
- All use centralized-rules
- All use beads

**Developer A (human):**
```bash
# Morning
bd ready --json
bd update bd-42 --status in_progress --json

# Work...
# Discover bug
bd create "Fix memory leak" -t bug -p0 --json
bd dep add bd-50 bd-42 --type discovered-from

# Critical bug, switch to it
bd update bd-50 --status in_progress --json
# Fix...
bd close bd-50 --reason "Fixed memory leak in connection pool" --json

# Back to original
bd close bd-42 --reason "Completed auth" --json
bd sync && git push
```

**Developer B (AI agent with centralized-rules):**
```
User (Developer B): "What should I work on?"

AI:
Let me check available work...
bd ready --json

I see bd-51 [P0] "Fix memory leak" is available.
This was discovered by Developer A while working on bd-42.
It's P0, so highest priority.

Shall I work on this?
```

**Result:** Consistent workflow across human and AI team members.

## Recommendations for End Users

### For New Beads Users

1. **Sync centralized-rules:** Run `sync-ai-rules.sh` in your beads project
2. **Check AGENTS.md:** Read `.claude/AGENTS.md` to see beads rule is available
3. **Start session with AI:** Say "let's start working" - AI will load beads rule
4. **Let AI guide you:** AI knows the session protocols, follow its lead
5. **Trust the integration:** AI understands how beads, git, testing, and TodoWrite work together

### For Existing Beads Users

1. **Sync rules:** Your AI agent will now follow consistent beads workflows
2. **Session boundaries:** AI will help with session start/end protocols
3. **Discovered work:** AI will automatically file discovered bugs/tasks
4. **Quality gates:** AI won't let you close issues with failing tests
5. **Team consistency:** All team members using centralized-rules follow same patterns

### For Rule Maintainers

1. **Keep rule updated:** As beads evolves, update `tools/beads/issue-tracking.md`
2. **Monitor rule size:** Currently 20KB - try to keep under 25KB
3. **Add examples:** As new patterns emerge, add to examples section
4. **Integration docs:** Keep integration section current as other rules change
5. **User feedback:** Collect feedback on "when to load" criteria

## Token Efficiency Metrics

### Current Implementation

**Single session with beads:**
```
Session start:
  Beads rule: 20KB
  Git workflow: 8KB
  Subtotal: 28KB

Work on Python/FastAPI task:
  Python standards: 12KB
  FastAPI practices: 10KB
  Testing philosophy: 15KB
  Subtotal: 37KB

Session end:
  (Rules already loaded)
  Subtotal: 0KB

Total session: 65KB rules, 135KB for code (67% efficiency)
```

**Without progressive disclosure (if beads always loaded):**
```
Every task loads:
  Beads: 20KB (not needed for every task)
  Python: 12KB
  FastAPI: 10KB
  Testing: 15KB
  Total: 57KB

10 tasks: 570KB total
With progressive disclosure: 65KB
Savings: 505KB (8.8x improvement!)
```

### Best Case Scenario

**Short session, one task, no beads context needed:**
```
Without beads rule:
  Python: 12KB
  FastAPI: 10KB
  Total: 22KB
  Code space: 178KB (89% efficiency)

With always-loaded beads:
  Beads: 20KB
  Python: 12KB
  FastAPI: 10KB
  Total: 42KB
  Code space: 158KB (79% efficiency)

Progressive disclosure wins: 10% better
```

### Worst Case Scenario

**Complex session with multiple technologies and session boundaries:**
```
Session start:
  Beads: 20KB

Work on backend:
  Python: 12KB
  FastAPI: 10KB

Work on frontend:
  TypeScript: 12KB
  React: 14KB

Session end:
  (Already loaded)

Total: 68KB
Code space: 132KB (66% efficiency)

Still acceptable for complex sessions!
```

## Conclusion

The beads integration is **production-ready** with strong progressive disclosure:

âœ… **Well-integrated:** Detection, loading, documentation all working
âœ… **User-friendly:** AGENTS.md guides AI agents on when to load
âœ… **Token-efficient:** 20KB loaded selectively, not always
âœ… **Well-documented:** Integration with git/testing/TodoWrite explained
âœ… **Team-ready:** Consistent workflows across human and AI developers

**Key success factor:** Progressive disclosure strategy ensures beads rule is loaded when needed (session boundaries) but not for every task, maintaining token efficiency while providing comprehensive guidance.

**Next steps for users:**
1. Sync centralized-rules in beads projects
2. Let AI agents manage session protocols
3. Focus on coding, let beads + AI handle workflow
4. Trust the integration - it's all designed to work together

**Next steps for maintainers:**
1. Monitor user feedback on "when to load" criteria
2. Refine integration docs based on real usage
3. Keep rule size under 25KB
4. Add more examples as patterns emerge
